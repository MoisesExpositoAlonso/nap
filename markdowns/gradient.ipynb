{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Additive Polygenic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that genotypes are stored in a $N \\times L$ matrix, where $N$ is the number of individuals and $L$ is the number of loci. The model has the following parameters:\n",
    "\n",
    "$s$, vector of effect sizes for different loci\n",
    "\n",
    "$e$, power term that controls linearity\n",
    "\n",
    "$a^2$, variance of the Gaussian error term (which has mean $0$)\n",
    "$b^2$, variance increase of the Gaussian error term (as commonly seen in Poisson-liked distributions)\n",
    "\n",
    "$\\mu$, population-wide mean\n",
    "\n",
    "We define the mean for individual $i$ as\n",
    "\n",
    "$$\\w_i = sgn(b_i)|b_i|^\\alpha + \\mu,$$\n",
    "where $b_i = \\beta^T X_i = \\sum_j \\beta_j X_{ij}$. Alternatively, we write the phenotype $Y_i$ for individual $i$ as \n",
    "\n",
    "$$Y_i = sgn(b_i)|b_i|^\\alpha + \\mu + \\epsilon_i,$$\n",
    "where $\\epsilon_i$ is the Gaussian error for individual $i$.\n",
    "\n",
    "In this model, the loglikelihood is\n",
    "\\begin{align*}\n",
    "LL(\\theta) &= \\sum_{i=1}^n \\log P(Y_i \\mid \\theta) \\\\\n",
    "&= \\sum_{i=1}^n \\log \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(Y_i-\\mu_i)^2}{2\\sigma^2}\\right)\\\\\n",
    "&= -\\frac{n}{2}\\log 2 \\pi \\sigma^2 - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n \\left(Y_i-\\mu_i\\right)^2.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradients\n",
    "\n",
    "First, the gradient for the effect size $\\beta_l$. Defining operator $D := \\frac{\\delta}{\\delta \\beta_l}$,\n",
    "\n",
    "\\begin{align*}\n",
    "DLL(\\theta) &= D\\left(-n\\log \\sqrt{2 \\pi \\sigma^2} - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n \\left(Y_i-\\mu_i\\right)^2\\right)\\\\\n",
    "&= -\\frac{1}{2\\sigma ^2}\\sum_{i=1}^n D(Y_i-\\mu_i)^2 \\\\\n",
    "&= \\frac{1}{2\\sigma^2} \\sum_{i=1}^n 2(Y_i-\\mu_i)D\\mu_i\n",
    "\\end{align*}\n",
    "\n",
    "We have\n",
    "\n",
    "\\begin{align*}\n",
    "D\\mu_i &= D\\left[ sgn(b_i) |b_i|^\\alpha  \\right] \\\\\n",
    "\\end{align*}\n",
    "where $b = \\sum_{j=1}^k \\beta_j G_{ij}$ and $sgn(x)$ is the sign function. We have $D sgn(b_i) = 0$, so, by the product rule,\n",
    "\n",
    "\\begin{align*}\n",
    "D \\mu_i &= sgn(b) D\\left(|b_i|^\\alpha\\right) \\\\\n",
    "&= sgn(b_i)\\alpha |b_i|^{\\alpha-1} D|b_i|\\\\\n",
    "&= sgn(b_i)\\alpha |b_i|^{\\alpha-1}sgn(b_i)G_{il}\\\\\n",
    "&= \\alpha |b_i|^{\\alpha-1} G_{il}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "And thus\n",
    "\\begin{align*}\n",
    "&= DLL(\\theta) = \\frac{\\alpha}{\\sigma^2} \\sum_{i=1}^n\\left(Y_i-\\mu_i\\right)\\left|\\sum_{j=1}^k \\beta_j G_{ij}\\right|^{\\alpha-1} \\cdot G_{il}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to calculate with respect to $\\mu$, $\\sigma^2$ and $\\alpha$.\n",
    "\n",
    "#### For $\\alpha$\n",
    "\n",
    "Defining $D:= \\frac{\\delta}{\\delta \\alpha}$, we again have\n",
    "\n",
    "\\begin{align}\n",
    "DLL(\\theta) &= \\frac{1}{2\\sigma^2}\\sum_{i=1}^n2(Y_i-\\mu_i)D\\mu_i \\\\\n",
    "\\end{align}\n",
    "\n",
    "We can calculate \n",
    "\n",
    "\\begin{align*}\n",
    "D\\mu_i &= D\\big(sgn(b)|b|^\\alpha + \\mu\\big)\\\\\n",
    "&= sgn(b)|b|^\\alpha \\log|b|\n",
    "\\end{align*}\n",
    "where again $b = \\sum_{j=1}^k \\beta_j G_{ij}$.  (And all the log's are base $e$.) Thus\n",
    "\n",
    "$$\\frac{\\delta}{\\delta \\alpha}LL(\\theta) = \\frac{1}{\\sigma^2}\\sum_{i=1}^n (Y_i-\\mu_i)sgn(b_i)|b_i|^\\alpha \\log |b|.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For $\\mu$\n",
    "\n",
    "Defining $D:= \\frac{\\delta}{\\delta \\mu}$, we again have\n",
    "\n",
    "\\begin{align}\n",
    "DLL(\\theta) &= \\frac{1}{2\\sigma^2}\\sum_{i=1}^n2(X_i-\\mu_i)D\\mu_i \\\\\n",
    "\\end{align}\n",
    "\n",
    "We can calculate \n",
    "\n",
    "\\begin{align*}\n",
    "D\\mu_i &= D\\big(sgn(b)|b|^\\alpha + \\mu\\big)\\\\\n",
    "&= 1\n",
    "\\end{align*}\n",
    "\n",
    "and thus\n",
    "\n",
    "$$\\frac{\\delta}{\\delta \\mu} LL(\\theta) = \\frac{1}{\\sigma^2}\\sum_{i=1}^n(X_i-\\mu_i)$$.\n",
    "\n",
    "#### For $\\sigma^2$  (remembering to ignore the squared, since it's just part of the parameter's name)\n",
    "\n",
    "Defining $D:= \\frac{\\delta}{\\delta \\sigma^2}$, we again have\n",
    "\n",
    "\\begin{align}\n",
    "DLL(\\theta) &= D\\left(-n\\log \\sqrt{2 \\pi \\sigma^2} - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n \\left(X_i-\\mu_i\\right)^2\\right)\\\\\n",
    "&= -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\left(X_i-\\mu_i\\right)^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking the gradient numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import approx_fprime\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "G = npr.choice([-1,0,1], size = k, replace = True)\n",
    "beta = npr.uniform(-1,1, size = k)\n",
    "mu_0 = 4.5\n",
    "alpha = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_i(betas):\n",
    "    b = np.sum(betas*G)\n",
    "    absb = np.abs(b)\n",
    "    sgnb = np.sign(b)\n",
    "    return sgnb * absb**alpha + mu_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Dmu_i(betas):\n",
    "    absb = np.abs(np.sum(betas*G))\n",
    "    return alpha*(absb**(alpha-1.0))*G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.932148169982433"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_i(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , -28.06526389,  28.06526389, -28.06526389,\n",
       "       -28.06526389,  28.06526389,  28.06526389, -28.06526389,\n",
       "       -28.06526389,  28.06526389])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_fprime(beta, mu_i, 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , -28.06526173,  28.06526173, -28.06526173,\n",
       "       -28.06526173,  28.06526173,  28.06526173, -28.06526173,\n",
       "       -28.06526173,  28.06526173])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dmu_i(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
